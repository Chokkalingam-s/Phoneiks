import React, { createContext, useContext, useRef, useState, useEffect } from "react";
import { useNavigate, useLocation } from "react-router-dom";

const VoiceContext = createContext();

export const useVoice = () => useContext(VoiceContext);

const messages = {
  en: {
    combined:
      "Welcome to Phoeniks. For voice Guidance Say 'Enable Voice aid' or click 'Enable button'.",
    enabled:
      "Voice guidance activated. This website is developed for specially abled individuals across India. Apply UDID if not registered yet.",
  },
  hi: {
    combined:
      "‡§´‡•Ä‡§®‡§ø‡§ï‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§µ‡•â‡§á‡§∏ ‡§ó‡§æ‡§á‡§° ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§π‡•á‡§Ç '‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§ï‡§∞‡•á‡§Ç' ‡§Ø‡§æ '‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§ï‡§∞‡•á‡§Ç' ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç‡•§",
    enabled:
      "‡§µ‡•â‡§á‡§∏ ‡§ó‡§æ‡§á‡§°‡•á‡§Ç‡§∏ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§ï‡§∞ ‡§¶‡•Ä ‡§ó‡§à ‡§π‡•à‡•§ ‡§Ø‡§π ‡§µ‡•á‡§¨‡§∏‡§æ‡§á‡§ü ‡§≠‡§æ‡§∞‡§§ ‡§≠‡§∞ ‡§ï‡•á ‡§¶‡§ø‡§µ‡•ç‡§Ø‡§æ‡§Ç‡§ó ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§ï‡•Ä ‡§ó‡§à ‡§π‡•à‡•§ ‡§Ø‡§¶‡§ø ‡§Ö‡§≠‡•Ä ‡§§‡§ï ‡§™‡§Ç‡§ú‡•Ä‡§ï‡§∞‡§£ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à ‡§§‡•ã ‡§Ø‡•Ç‡§°‡•Ä‡§Ü‡§à‡§°‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§µ‡•á‡§¶‡§® ‡§ï‡§∞‡•á‡§Ç‡•§",
  },
};

function speak(msg, lang = "en-IN") {
  return new Promise((resolve) => {
    console.log("üîä [SPEAK] Starting speech for:", msg.substring(0, 50));
    
    // Force cancel any ongoing speech
    window.speechSynthesis.cancel();
    
    // Wait for cancel to complete, then speak
    setTimeout(() => {
      const utter = new window.SpeechSynthesisUtterance(msg);
      utter.lang = lang;
      utter.rate = 0.9;
      utter.pitch = 1.0;
      utter.volume = 1.0;
      
      utter.onstart = () => {
        console.log("üîä [SPEAK] ‚úÖ Audio STARTED");
      };
      
      utter.onend = () => {
        console.log("üîä [SPEAK] ‚úÖ Audio ENDED");
        setTimeout(resolve, 100);
      };
      
      utter.onerror = (e) => {
        console.error("üîä [SPEAK] ‚ùå ERROR:", e.error);
        setTimeout(resolve, 100);
      };
      
      console.log("üîä [SPEAK] Calling speechSynthesis.speak()");
      window.speechSynthesis.speak(utter);
      
      // Verify it's queued
      setTimeout(() => {
        console.log("üîä [SPEAK] Speaking:", window.speechSynthesis.speaking);
        console.log("üîä [SPEAK] Pending:", window.speechSynthesis.pending);
      }, 100);
    }, 200);
  });
}

function getLangCode(s) {
  s = s.toLowerCase();
  if (/aawaaz|saksham|‡§Ü‡§µ‡§æ‡§ú‡§º|‡§Ü‡§µ‡§æ‡§ú|hindi/i.test(s)) return "hi";
  return "en";
}

export function VoiceProvider({ children }) {
  const navigate = useNavigate();
  const location = useLocation();

  const [voiceEnabled, setVoiceEnabled] = useState(false);
  const [chosenLang, setChosenLang] = useState("en");

  const voiceEnabledRef = useRef(false);
  const chosenLangRef = useRef("en");
  const recognitionRef = useRef(null);
  const restartTimeoutRef = useRef(null);
  const isSpeakingRef = useRef(false);
  const isStoppingRef = useRef(false);

  useEffect(() => {
    if (voiceEnabled && !recognitionRef.current && !isSpeakingRef.current) {
      console.log("üéôÔ∏è [CONTEXT] Starting recognition from context");
      startRecognition();
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
        recognitionRef.current = null;
      }
      if (restartTimeoutRef.current) {
        clearTimeout(restartTimeoutRef.current);
      }
      window.speechSynthesis.cancel();
    };
  }, [voiceEnabled]);

  useEffect(() => {
    if (voiceEnabled) {
      console.log("üìç [ROUTE] Changed to:", location.pathname);
    }
  }, [location.pathname, voiceEnabled]);

  async function stopRecognitionForSpeech() {
    if (isStoppingRef.current) {
      console.log("‚ö†Ô∏è [STOP] Already stopping, waiting...");
      await new Promise(resolve => setTimeout(resolve, 500));
      return;
    }
    
    isStoppingRef.current = true;
    console.log("üõë [STOP] Stopping recognition for speech");
    
    // Clear any restart timeouts
    if (restartTimeoutRef.current) {
      clearTimeout(restartTimeoutRef.current);
      restartTimeoutRef.current = null;
    }
    
    // Stop recognition
    if (recognitionRef.current) {
      try {
        recognitionRef.current.abort();
        recognitionRef.current.stop();
        console.log("üõë [STOP] Recognition stopped");
      } catch (e) {
        console.error("üõë [STOP] Error:", e);
      }
      recognitionRef.current = null;
    }
    
    // Wait for recognition to fully stop
    await new Promise(resolve => setTimeout(resolve, 500));
    console.log("üõë [STOP] Complete");
    isStoppingRef.current = false;
  }

  function startRecognition() {
    if (!("webkitSpeechRecognition" in window || "SpeechRecognition" in window)) {
      console.log("‚ùå [START] Speech recognition not supported");
      return;
    }

    if (recognitionRef.current) {
      console.log("‚ö†Ô∏è [START] Recognition already running");
      return;
    }

    if (isSpeakingRef.current) {
      console.log("‚ö†Ô∏è [START] Currently speaking, delaying start");
      return;
    }

    console.log("‚ñ∂Ô∏è [START] Starting new recognition");
    
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    const recog = new SpeechRecognition();

    recog.continuous = true;
    recog.interimResults = false;
    recog.maxAlternatives = 3;
    recog.lang = chosenLangRef.current === "hi" ? "hi-IN" : "en-IN";

    recog.onstart = () => {
      console.log("‚ñ∂Ô∏è [START] Recognition ACTIVE");
    };

    recog.onresult = function (event) {
      if (isSpeakingRef.current) {
        console.log("‚è∏Ô∏è [RESULT] Speaking in progress, ignoring");
        return;
      }

      for (let i = event.resultIndex; i < event.results.length; i++) {
        if (!event.results[i].isFinal) continue;

        const transcript = event.results[i][0].transcript.trim().toLowerCase();
        console.log("üé§ [RESULT] Captured:", transcript);

        // Enable voice aid command
        if (!voiceEnabledRef.current) {
          const enableCmdRegex = /(enable|voice|aid|guidance|aawaaz|‡§Ü‡§µ‡§æ‡§ú‡§º|‡§Ü‡§µ‡§æ‡§ú|saksham|‡§∏‡§ï‡•ç‡§∑‡§Æ|chalu|‡§ö‡§æ‡§≤‡•Ç|karein|‡§ï‡§∞‡•á‡§Ç)/i;

          if (enableCmdRegex.test(transcript)) {
            console.log("üîä [RESULT] Triggering enableVoice");
            enableVoice(getLangCode(transcript));
            return;
          }
        }

        // Navigation commands
        if (voiceEnabledRef.current) {
          // Home navigation
          if (/home|‡§π‡•ã‡§Æ|go home|go to home/i.test(transcript)) {
            console.log("üè† [RESULT] Triggering HOME navigation");
            handleNavigation("/home", "home");
            return;
          }

          // Login navigation
          if (/login|‡§≤‡•â‡§ó‡§ø‡§®|log in|go to login/i.test(transcript)) {
            console.log("üîê [RESULT] Triggering LOGIN navigation");
            handleNavigation("/pwd-login", "login");
            return;
          }

          // Apply UDID navigation
          if (/apply|‡§Ø‡•Ç‡§°‡•Ä‡§Ü‡§à‡§°‡•Ä|udid|apply udid|apply for udid/i.test(transcript)) {
            console.log("üìù [RESULT] Triggering APPLY navigation");
            handleNavigation("/apply-for-udid", "apply");
            return;
          }
        }
      }
    };

    recog.onerror = function (e) {
      console.log("‚ùå [ERROR] Recognition error:", e.error);

      if (e.error === "aborted" || e.error === "no-speech") {
        return;
      }

      if (voiceEnabledRef.current && !isSpeakingRef.current) {
        restartTimeoutRef.current = setTimeout(() => {
          if (!recognitionRef.current && !isSpeakingRef.current) {
            console.log("üîÑ [ERROR] Restarting after error");
            startRecognition();
          }
        }, 1000);
      }
    };

    recog.onend = function () {
      console.log("‚èπÔ∏è [END] Recognition ended");
      recognitionRef.current = null;

      if (voiceEnabledRef.current && !isSpeakingRef.current && !isStoppingRef.current) {
        restartTimeoutRef.current = setTimeout(() => {
          if (!recognitionRef.current && !isSpeakingRef.current) {
            console.log("üîÑ [END] Auto-restarting");
            startRecognition();
          }
        }, 500);
      }
    };

    try {
      recog.start();
      recognitionRef.current = recog;
      console.log("‚ñ∂Ô∏è [START] Recognition object created and started");
    } catch (err) {
      console.log("‚ùå [START] Error:", err);
    }
  }

  async function handleNavigation(path, pageName) {
    console.log(`\nüöÄ [NAV] ===== NAVIGATION TO ${pageName.toUpperCase()} STARTED =====`);
    
    // Set speaking flag FIRST
    isSpeakingRef.current = true;
    
    // Stop recognition and wait
    await stopRecognitionForSpeech();
    
    console.log(`üîä [NAV] Preparing speech for ${pageName}`);

    const msg =
      chosenLangRef.current === "hi"
        ? `${pageName === "home" ? "‡§π‡•ã‡§Æ" : pageName === "login" ? "‡§≤‡•â‡§ó‡§ø‡§®" : "‡§Ö‡§™‡•ç‡§≤‡§æ‡§à"} ‡§™‡•á‡§ú ‡§™‡§∞ ‡§ú‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç`
        : `Navigating to ${pageName} page`;

    console.log(`üîä [NAV] Message: "${msg}"`);
    
    // Speak and wait for completion
    await speak(msg, chosenLangRef.current === "hi" ? "hi-IN" : "en-IN");
    
    console.log(`‚úÖ [NAV] Speech completed for ${pageName}`);
    console.log(`üîÄ [NAV] Navigating to ${path}`);
    
    navigate(path);
    
    // Clear speaking flag
    isSpeakingRef.current = false;
    
    // Resume recognition with delay
    console.log(`‚ñ∂Ô∏è [NAV] Scheduling recognition restart in 1.5s`);
    setTimeout(() => {
      if (voiceEnabledRef.current && !isSpeakingRef.current) {
        console.log("‚ñ∂Ô∏è [NAV] Resuming recognition after navigation");
        startRecognition();
      }
    }, 1500);
    
    console.log(`üöÄ [NAV] ===== NAVIGATION TO ${pageName.toUpperCase()} COMPLETE =====\n`);
  }

  async function enableVoice(lang = "en") {
    if (voiceEnabledRef.current) return;

    console.log("\n‚úÖ [ENABLE] ===== ENABLING VOICE =====");
    console.log("‚úÖ [ENABLE] Language:", lang);

    // Set speaking flag FIRST
    isSpeakingRef.current = true;
    
    // Stop recognition and wait
    await stopRecognitionForSpeech();

    setVoiceEnabled(true);
    voiceEnabledRef.current = true;

    setChosenLang(lang);
    chosenLangRef.current = lang;

    console.log("üîä [ENABLE] Preparing enabled message");
    
    // Speak the enabled message
    await speak(messages[lang].enabled, lang + "-IN");
    
    console.log("‚úÖ [ENABLE] Speech completed");
    
    // Clear speaking flag
    isSpeakingRef.current = false;

    // Start recognition with delay
    console.log("‚ñ∂Ô∏è [ENABLE] Scheduling recognition start in 1.5s");
    setTimeout(() => {
      if (voiceEnabledRef.current && !isSpeakingRef.current) {
        console.log("üîÑ [ENABLE] Starting recognition");
        startRecognition();
      }
    }, 1500);
    
    console.log("‚úÖ [ENABLE] ===== VOICE ENABLED =====\n");
  }

  function disableVoice() {
    console.log("üîá [DISABLE] Disabling voice");

    setVoiceEnabled(false);
    voiceEnabledRef.current = false;

    stopRecognitionForSpeech();
    window.speechSynthesis.cancel();
  }

  const value = {
    voiceEnabled,
    chosenLang,
    enableVoice,
    disableVoice,
    speak: async (msg) => {
      isSpeakingRef.current = true;
      await stopRecognitionForSpeech();
      await speak(msg, chosenLangRef.current === "hi" ? "hi-IN" : "en-IN");
      isSpeakingRef.current = false;
      
      setTimeout(() => {
        if (voiceEnabledRef.current && !isSpeakingRef.current) {
          startRecognition();
        }
      }, 1500);
    },
  };

  return <VoiceContext.Provider value={value}>{children}</VoiceContext.Provider>;
}
